{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn pandas joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            cough       1.00      0.80      0.89         5\n",
      "         coughing       0.00      0.00      0.00         6\n",
      "          falling       0.83      0.71      0.77        14\n",
      "         headache       0.72      0.95      0.82        19\n",
      "     heart stroke       0.79      0.68      0.73        22\n",
      "          sitting       0.75      0.94      0.83        16\n",
      "         standing       1.00      0.71      0.83         7\n",
      "standing normally       1.00      1.00      1.00         8\n",
      "\n",
      "         accuracy                           0.77        97\n",
      "        macro avg       0.76      0.72      0.73        97\n",
      "     weighted avg       0.77      0.77      0.76        97\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['activity_classifier.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "data = pd.read_csv('pose_data.csv') \n",
    "\n",
    "X = data.drop(columns=['Label'])  \n",
    "y = data['Label']                \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "joblib.dump(model, 'activity_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import numpy as np\n",
    "# import joblib\n",
    "# import time\n",
    "\n",
    "# model = joblib.load('activity_classifier.pkl')\n",
    "# scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# mp_pose = mp.solutions.pose\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# def predict_activity(landmarks):\n",
    "#     feature_vector = []\n",
    "#     for landmark in landmarks:\n",
    "#         feature_vector.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "    \n",
    "#     feature_vector = np.array(feature_vector).reshape(1, -1)\n",
    "#     feature_vector = scaler.transform(feature_vector)\n",
    "    \n",
    "#     activity = model.predict(feature_vector)\n",
    "#     return activity[0]\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(\"Ignoring empty frame.\")\n",
    "#             break\n",
    "\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image.flags.writeable = False\n",
    "\n",
    "#         results = pose.process(image)\n",
    "\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#         if results.pose_landmarks:\n",
    "#             mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "#             landmarks = results.pose_landmarks.landmark\n",
    "#             activity = predict_activity(landmarks)\n",
    "#         else:\n",
    "#             activity = \"No Person Detected\"\n",
    "\n",
    "#         cv2.putText(image, f\"Activity: {activity}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "#         cv2.imshow('Real-time Activity Detection', image)\n",
    "\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('pose_data.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop(columns=['Label'])\n",
    "y = data['Label']\n",
    "\n",
    "# Encode labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Save label encoder for future use\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# One-hot encode the labels for deep learning\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Train-test split (using stratify for balanced classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_one_hot, test_size=0.2, random_state=42, stratify=y_one_hot\n",
    ")\n",
    "\n",
    "# Build the deep learning model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_one_hot.shape[1], activation='softmax')  # Output layer with softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot encoded test labels back to integers\n",
    "\n",
    "# Handle the classification report\n",
    "labels = np.unique(y_test_labels)\n",
    "print(\"Classification Report:\\n\", classification_report(\n",
    "    y_test_labels,\n",
    "    y_pred,\n",
    "    labels=labels,\n",
    "    target_names=label_encoder.inverse_transform(labels)\n",
    "))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('activity_classifier_deep.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anacondadata\\envs\\human\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 240ms/step - accuracy: 0.1451 - loss: 3.0752 - val_accuracy: 0.3500 - val_loss: 2.1569 - learning_rate: 0.0010\n",
      "Epoch 2/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4415 - loss: 2.0989 - val_accuracy: 0.5500 - val_loss: 1.8473 - learning_rate: 0.0010\n",
      "Epoch 3/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5813 - loss: 1.6968 - val_accuracy: 0.6000 - val_loss: 1.6127 - learning_rate: 0.0010\n",
      "Epoch 4/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6609 - loss: 1.3404 - val_accuracy: 0.7000 - val_loss: 1.4192 - learning_rate: 0.0010\n",
      "Epoch 5/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7280 - loss: 1.2430 - val_accuracy: 0.7500 - val_loss: 1.2595 - learning_rate: 0.0010\n",
      "Epoch 6/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8780 - loss: 0.9105 - val_accuracy: 0.9250 - val_loss: 1.1328 - learning_rate: 0.0010\n",
      "Epoch 7/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8670 - loss: 0.8274 - val_accuracy: 1.0000 - val_loss: 1.0309 - learning_rate: 0.0010\n",
      "Epoch 8/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8656 - loss: 0.9118 - val_accuracy: 1.0000 - val_loss: 0.9557 - learning_rate: 0.0010\n",
      "Epoch 9/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9115 - loss: 0.7550 - val_accuracy: 1.0000 - val_loss: 0.8940 - learning_rate: 0.0010\n",
      "Epoch 10/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8935 - loss: 0.7876 - val_accuracy: 1.0000 - val_loss: 0.8469 - learning_rate: 0.0010\n",
      "Epoch 11/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9161 - loss: 0.7482 - val_accuracy: 1.0000 - val_loss: 0.8119 - learning_rate: 0.0010\n",
      "Epoch 12/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9523 - loss: 0.6724 - val_accuracy: 1.0000 - val_loss: 0.7793 - learning_rate: 0.0010\n",
      "Epoch 13/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9141 - loss: 0.7437 - val_accuracy: 1.0000 - val_loss: 0.7523 - learning_rate: 0.0010\n",
      "Epoch 14/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9090 - loss: 0.6429 - val_accuracy: 1.0000 - val_loss: 0.7272 - learning_rate: 0.0010\n",
      "Epoch 15/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9536 - loss: 0.6363 - val_accuracy: 1.0000 - val_loss: 0.7036 - learning_rate: 0.0010\n",
      "Epoch 16/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9438 - loss: 0.6712 - val_accuracy: 1.0000 - val_loss: 0.6868 - learning_rate: 0.0010\n",
      "Epoch 17/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9865 - loss: 0.5764 - val_accuracy: 1.0000 - val_loss: 0.6718 - learning_rate: 0.0010\n",
      "Epoch 18/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9458 - loss: 0.6153 - val_accuracy: 1.0000 - val_loss: 0.6549 - learning_rate: 0.0010\n",
      "Epoch 19/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9683 - loss: 0.5723 - val_accuracy: 1.0000 - val_loss: 0.6431 - learning_rate: 0.0010\n",
      "Epoch 20/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9490 - loss: 0.6270 - val_accuracy: 1.0000 - val_loss: 0.6348 - learning_rate: 0.0010\n",
      "Epoch 21/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9625 - loss: 0.6046 - val_accuracy: 1.0000 - val_loss: 0.6199 - learning_rate: 0.0010\n",
      "Epoch 22/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9833 - loss: 0.5373 - val_accuracy: 1.0000 - val_loss: 0.6040 - learning_rate: 0.0010\n",
      "Epoch 23/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9600 - loss: 0.5888 - val_accuracy: 1.0000 - val_loss: 0.5915 - learning_rate: 0.0010\n",
      "Epoch 24/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9948 - loss: 0.5215 - val_accuracy: 1.0000 - val_loss: 0.5769 - learning_rate: 0.0010\n",
      "Epoch 25/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9858 - loss: 0.5285 - val_accuracy: 1.0000 - val_loss: 0.5649 - learning_rate: 0.0010\n",
      "Epoch 26/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9548 - loss: 0.5718 - val_accuracy: 1.0000 - val_loss: 0.5556 - learning_rate: 0.0010\n",
      "Epoch 27/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9509 - loss: 0.5893 - val_accuracy: 1.0000 - val_loss: 0.5527 - learning_rate: 0.0010\n",
      "Epoch 28/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9730 - loss: 0.5536 - val_accuracy: 1.0000 - val_loss: 0.5498 - learning_rate: 0.0010\n",
      "Epoch 29/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9651 - loss: 0.5359 - val_accuracy: 1.0000 - val_loss: 0.5497 - learning_rate: 0.0010\n",
      "Epoch 30/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9600 - loss: 0.5620 - val_accuracy: 1.0000 - val_loss: 0.5488 - learning_rate: 0.0010\n",
      "Epoch 31/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9676 - loss: 0.5244 - val_accuracy: 1.0000 - val_loss: 0.5444 - learning_rate: 0.0010\n",
      "Epoch 32/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9774 - loss: 0.5267 - val_accuracy: 1.0000 - val_loss: 0.5324 - learning_rate: 0.0010\n",
      "Epoch 33/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9806 - loss: 0.5196 - val_accuracy: 1.0000 - val_loss: 0.5255 - learning_rate: 0.0010\n",
      "Epoch 34/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9845 - loss: 0.5054 - val_accuracy: 1.0000 - val_loss: 0.5173 - learning_rate: 0.0010\n",
      "Epoch 35/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.4791 - val_accuracy: 1.0000 - val_loss: 0.5094 - learning_rate: 0.0010\n",
      "Epoch 36/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9858 - loss: 0.5130 - val_accuracy: 1.0000 - val_loss: 0.5050 - learning_rate: 0.0010\n",
      "Epoch 37/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9605 - loss: 0.5234 - val_accuracy: 1.0000 - val_loss: 0.4952 - learning_rate: 0.0010\n",
      "Epoch 38/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9787 - loss: 0.5125 - val_accuracy: 1.0000 - val_loss: 0.4826 - learning_rate: 0.0010\n",
      "Epoch 39/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9762 - loss: 0.5034 - val_accuracy: 1.0000 - val_loss: 0.4734 - learning_rate: 0.0010\n",
      "Epoch 40/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9897 - loss: 0.4827 - val_accuracy: 1.0000 - val_loss: 0.4681 - learning_rate: 0.0010\n",
      "Epoch 41/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9909 - loss: 0.4979 - val_accuracy: 1.0000 - val_loss: 0.4638 - learning_rate: 0.0010\n",
      "Epoch 42/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9948 - loss: 0.4783 - val_accuracy: 1.0000 - val_loss: 0.4630 - learning_rate: 0.0010\n",
      "Epoch 43/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9716 - loss: 0.4916 - val_accuracy: 1.0000 - val_loss: 0.4663 - learning_rate: 0.0010\n",
      "Epoch 44/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.4717 - val_accuracy: 1.0000 - val_loss: 0.4683 - learning_rate: 0.0010\n",
      "Epoch 45/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9826 - loss: 0.4919 - val_accuracy: 1.0000 - val_loss: 0.4657 - learning_rate: 0.0010\n",
      "Epoch 46/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9852 - loss: 0.4813 - val_accuracy: 1.0000 - val_loss: 0.4569 - learning_rate: 0.0010\n",
      "Epoch 47/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9833 - loss: 0.4926 - val_accuracy: 1.0000 - val_loss: 0.4522 - learning_rate: 0.0010\n",
      "Epoch 48/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9948 - loss: 0.4736 - val_accuracy: 1.0000 - val_loss: 0.4472 - learning_rate: 0.0010\n",
      "Epoch 49/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9619 - loss: 0.5223 - val_accuracy: 1.0000 - val_loss: 0.4429 - learning_rate: 0.0010\n",
      "Epoch 50/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9936 - loss: 0.4667 - val_accuracy: 1.0000 - val_loss: 0.4378 - learning_rate: 0.0010\n",
      "Epoch 51/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9877 - loss: 0.4788 - val_accuracy: 1.0000 - val_loss: 0.4365 - learning_rate: 0.0010\n",
      "Epoch 52/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9909 - loss: 0.4579 - val_accuracy: 1.0000 - val_loss: 0.4392 - learning_rate: 0.0010\n",
      "Epoch 53/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.4547 - val_accuracy: 1.0000 - val_loss: 0.4405 - learning_rate: 0.0010\n",
      "Epoch 54/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9948 - loss: 0.4570 - val_accuracy: 1.0000 - val_loss: 0.4395 - learning_rate: 0.0010\n",
      "Epoch 55/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9968 - loss: 0.4584 - val_accuracy: 1.0000 - val_loss: 0.4364 - learning_rate: 0.0010\n",
      "Epoch 56/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9877 - loss: 0.4667 - val_accuracy: 1.0000 - val_loss: 0.4334 - learning_rate: 0.0010\n",
      "Epoch 57/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9948 - loss: 0.4593 - val_accuracy: 1.0000 - val_loss: 0.4295 - learning_rate: 0.0010\n",
      "Epoch 58/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.4401 - val_accuracy: 1.0000 - val_loss: 0.4268 - learning_rate: 0.0010\n",
      "Epoch 59/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9948 - loss: 0.4490 - val_accuracy: 1.0000 - val_loss: 0.4271 - learning_rate: 0.0010\n",
      "Epoch 60/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9948 - loss: 0.4626 - val_accuracy: 1.0000 - val_loss: 0.4245 - learning_rate: 0.0010\n",
      "Epoch 61/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9936 - loss: 0.4583 - val_accuracy: 1.0000 - val_loss: 0.4225 - learning_rate: 0.0010\n",
      "Epoch 62/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.4514 - val_accuracy: 1.0000 - val_loss: 0.4229 - learning_rate: 0.0010\n",
      "Epoch 63/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.4351 - val_accuracy: 1.0000 - val_loss: 0.4229 - learning_rate: 0.0010\n",
      "Epoch 64/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9948 - loss: 0.4379 - val_accuracy: 1.0000 - val_loss: 0.4221 - learning_rate: 0.0010\n",
      "Epoch 65/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9877 - loss: 0.4530 - val_accuracy: 1.0000 - val_loss: 0.4183 - learning_rate: 0.0010\n",
      "Epoch 66/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.4362 - val_accuracy: 1.0000 - val_loss: 0.4161 - learning_rate: 0.0010\n",
      "Epoch 67/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.4311 - val_accuracy: 1.0000 - val_loss: 0.4137 - learning_rate: 0.0010\n",
      "Epoch 68/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9909 - loss: 0.4554 - val_accuracy: 1.0000 - val_loss: 0.4116 - learning_rate: 0.0010\n",
      "Epoch 69/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.4284 - val_accuracy: 1.0000 - val_loss: 0.4100 - learning_rate: 0.0010\n",
      "Epoch 70/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.4241 - val_accuracy: 1.0000 - val_loss: 0.4087 - learning_rate: 0.0010\n",
      "Epoch 71/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.4324 - val_accuracy: 1.0000 - val_loss: 0.4077 - learning_rate: 0.0010\n",
      "Epoch 72/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9916 - loss: 0.4373 - val_accuracy: 1.0000 - val_loss: 0.4059 - learning_rate: 0.0010\n",
      "Epoch 73/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.4308 - val_accuracy: 1.0000 - val_loss: 0.4040 - learning_rate: 0.0010\n",
      "Epoch 74/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9948 - loss: 0.4363 - val_accuracy: 1.0000 - val_loss: 0.4029 - learning_rate: 0.0010\n",
      "Epoch 75/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.4222 - val_accuracy: 1.0000 - val_loss: 0.4022 - learning_rate: 0.0010\n",
      "Epoch 76/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.4367 - val_accuracy: 1.0000 - val_loss: 0.4014 - learning_rate: 0.0010\n",
      "Epoch 77/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.4284 - val_accuracy: 1.0000 - val_loss: 0.4007 - learning_rate: 0.0010\n",
      "Epoch 78/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9968 - loss: 0.4399 - val_accuracy: 1.0000 - val_loss: 0.3993 - learning_rate: 0.0010\n",
      "Epoch 79/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9916 - loss: 0.4271 - val_accuracy: 1.0000 - val_loss: 0.3980 - learning_rate: 0.0010\n",
      "Epoch 80/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.4174 - val_accuracy: 1.0000 - val_loss: 0.3976 - learning_rate: 0.0010\n",
      "Epoch 81/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9968 - loss: 0.4225 - val_accuracy: 1.0000 - val_loss: 0.3973 - learning_rate: 0.0010\n",
      "Epoch 82/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9735 - loss: 0.4602 - val_accuracy: 1.0000 - val_loss: 0.3973 - learning_rate: 0.0010\n",
      "Epoch 83/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.4182 - val_accuracy: 1.0000 - val_loss: 0.3970 - learning_rate: 0.0010\n",
      "Epoch 84/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.4071 - val_accuracy: 1.0000 - val_loss: 0.3964 - learning_rate: 0.0010\n",
      "Epoch 85/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9916 - loss: 0.4378 - val_accuracy: 1.0000 - val_loss: 0.3959 - learning_rate: 0.0010\n",
      "Epoch 86/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9948 - loss: 0.4146 - val_accuracy: 1.0000 - val_loss: 0.3942 - learning_rate: 0.0010\n",
      "Epoch 87/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.4130 - val_accuracy: 1.0000 - val_loss: 0.3928 - learning_rate: 0.0010\n",
      "Epoch 88/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.4121 - val_accuracy: 1.0000 - val_loss: 0.3918 - learning_rate: 0.0010\n",
      "Epoch 89/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.4071 - val_accuracy: 1.0000 - val_loss: 0.3906 - learning_rate: 0.0010\n",
      "Epoch 90/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.3997 - val_accuracy: 1.0000 - val_loss: 0.3895 - learning_rate: 0.0010\n",
      "Epoch 91/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9948 - loss: 0.4160 - val_accuracy: 1.0000 - val_loss: 0.3885 - learning_rate: 0.0010\n",
      "Epoch 92/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9909 - loss: 0.4161 - val_accuracy: 1.0000 - val_loss: 0.3877 - learning_rate: 0.0010\n",
      "Epoch 93/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.4019 - val_accuracy: 1.0000 - val_loss: 0.3871 - learning_rate: 0.0010\n",
      "Epoch 94/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9968 - loss: 0.4040 - val_accuracy: 1.0000 - val_loss: 0.3862 - learning_rate: 0.0010\n",
      "Epoch 95/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.3998 - val_accuracy: 1.0000 - val_loss: 0.3850 - learning_rate: 0.0010\n",
      "Epoch 96/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9909 - loss: 0.4044 - val_accuracy: 1.0000 - val_loss: 0.3841 - learning_rate: 0.0010\n",
      "Epoch 97/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.3942 - val_accuracy: 1.0000 - val_loss: 0.3834 - learning_rate: 0.0010\n",
      "Epoch 98/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9909 - loss: 0.4048 - val_accuracy: 1.0000 - val_loss: 0.3827 - learning_rate: 0.0010\n",
      "Epoch 99/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.3953 - val_accuracy: 1.0000 - val_loss: 0.3820 - learning_rate: 0.0010\n",
      "Epoch 100/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9909 - loss: 0.4246 - val_accuracy: 1.0000 - val_loss: 0.3818 - learning_rate: 0.0010\n",
      "Epoch 101/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9968 - loss: 0.3987 - val_accuracy: 1.0000 - val_loss: 0.3814 - learning_rate: 0.0010\n",
      "Epoch 102/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9909 - loss: 0.4034 - val_accuracy: 1.0000 - val_loss: 0.3802 - learning_rate: 0.0010\n",
      "Epoch 103/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.3931 - val_accuracy: 1.0000 - val_loss: 0.3790 - learning_rate: 0.0010\n",
      "Epoch 104/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9909 - loss: 0.4145 - val_accuracy: 1.0000 - val_loss: 0.3777 - learning_rate: 0.0010\n",
      "Epoch 105/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9909 - loss: 0.4192 - val_accuracy: 1.0000 - val_loss: 0.3768 - learning_rate: 0.0010\n",
      "Epoch 106/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.3859 - val_accuracy: 1.0000 - val_loss: 0.3759 - learning_rate: 0.0010\n",
      "Epoch 107/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.3898 - val_accuracy: 1.0000 - val_loss: 0.3750 - learning_rate: 0.0010\n",
      "Epoch 108/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9968 - loss: 0.4136 - val_accuracy: 1.0000 - val_loss: 0.3742 - learning_rate: 0.0010\n",
      "Epoch 109/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.3883 - val_accuracy: 1.0000 - val_loss: 0.3742 - learning_rate: 0.0010\n",
      "Epoch 110/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.3868 - val_accuracy: 1.0000 - val_loss: 0.3758 - learning_rate: 0.0010\n",
      "Epoch 111/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.3829 - val_accuracy: 1.0000 - val_loss: 0.3779 - learning_rate: 0.0010\n",
      "Epoch 112/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9948 - loss: 0.3955 - val_accuracy: 1.0000 - val_loss: 0.3761 - learning_rate: 0.0010\n",
      "Epoch 113/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.3824 - val_accuracy: 1.0000 - val_loss: 0.3730 - learning_rate: 0.0010\n",
      "Epoch 114/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.3800 - val_accuracy: 1.0000 - val_loss: 0.3710 - learning_rate: 0.0010\n",
      "Epoch 115/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9948 - loss: 0.4004 - val_accuracy: 1.0000 - val_loss: 0.3694 - learning_rate: 0.0010\n",
      "Epoch 116/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.3855 - val_accuracy: 1.0000 - val_loss: 0.3681 - learning_rate: 0.0010\n",
      "Epoch 117/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.3783 - val_accuracy: 1.0000 - val_loss: 0.3672 - learning_rate: 0.0010\n",
      "Epoch 118/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.3793 - val_accuracy: 1.0000 - val_loss: 0.3663 - learning_rate: 0.0010\n",
      "Epoch 119/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.3730 - val_accuracy: 1.0000 - val_loss: 0.3655 - learning_rate: 0.0010\n",
      "Epoch 120/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9909 - loss: 0.3884 - val_accuracy: 1.0000 - val_loss: 0.3649 - learning_rate: 0.0010\n",
      "Epoch 121/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.3766 - val_accuracy: 1.0000 - val_loss: 0.3643 - learning_rate: 0.0010\n",
      "Epoch 122/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.3702 - val_accuracy: 1.0000 - val_loss: 0.3636 - learning_rate: 0.0010\n",
      "Epoch 123/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.3793 - val_accuracy: 1.0000 - val_loss: 0.3630 - learning_rate: 0.0010\n",
      "Epoch 124/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.3720 - val_accuracy: 1.0000 - val_loss: 0.3620 - learning_rate: 0.0010\n",
      "Epoch 125/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.3723 - val_accuracy: 1.0000 - val_loss: 0.3611 - learning_rate: 0.0010\n",
      "Epoch 126/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.3750 - val_accuracy: 1.0000 - val_loss: 0.3601 - learning_rate: 0.0010\n",
      "Epoch 127/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.3691 - val_accuracy: 1.0000 - val_loss: 0.3591 - learning_rate: 0.0010\n",
      "Epoch 128/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.3658 - val_accuracy: 1.0000 - val_loss: 0.3581 - learning_rate: 0.0010\n",
      "Epoch 129/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9948 - loss: 0.3737 - val_accuracy: 1.0000 - val_loss: 0.3572 - learning_rate: 0.0010\n",
      "Epoch 130/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.3707 - val_accuracy: 1.0000 - val_loss: 0.3563 - learning_rate: 0.0010\n",
      "Epoch 131/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.3678 - val_accuracy: 1.0000 - val_loss: 0.3554 - learning_rate: 0.0010\n",
      "Epoch 132/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.3614 - val_accuracy: 1.0000 - val_loss: 0.3545 - learning_rate: 0.0010\n",
      "Epoch 133/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.3650 - val_accuracy: 1.0000 - val_loss: 0.3536 - learning_rate: 0.0010\n",
      "Epoch 134/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.3630 - val_accuracy: 1.0000 - val_loss: 0.3526 - learning_rate: 0.0010\n",
      "Epoch 135/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.3670 - val_accuracy: 1.0000 - val_loss: 0.3518 - learning_rate: 0.0010\n",
      "Epoch 136/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9968 - loss: 0.3657 - val_accuracy: 1.0000 - val_loss: 0.3509 - learning_rate: 0.0010\n",
      "Epoch 137/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.3617 - val_accuracy: 1.0000 - val_loss: 0.3500 - learning_rate: 0.0010\n",
      "Epoch 138/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.3539 - val_accuracy: 1.0000 - val_loss: 0.3492 - learning_rate: 0.0010\n",
      "Epoch 139/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.3575 - val_accuracy: 1.0000 - val_loss: 0.3484 - learning_rate: 0.0010\n",
      "Epoch 140/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.3666 - val_accuracy: 1.0000 - val_loss: 0.3476 - learning_rate: 0.0010\n",
      "Epoch 141/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.3570 - val_accuracy: 1.0000 - val_loss: 0.3468 - learning_rate: 0.0010\n",
      "Epoch 142/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.3547 - val_accuracy: 1.0000 - val_loss: 0.3459 - learning_rate: 0.0010\n",
      "Epoch 143/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.3624 - val_accuracy: 1.0000 - val_loss: 0.3451 - learning_rate: 0.0010\n",
      "Epoch 144/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.3552 - val_accuracy: 1.0000 - val_loss: 0.3443 - learning_rate: 0.0010\n",
      "Epoch 145/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.3534 - val_accuracy: 1.0000 - val_loss: 0.3435 - learning_rate: 0.0010\n",
      "Epoch 146/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.3506 - val_accuracy: 1.0000 - val_loss: 0.3427 - learning_rate: 0.0010\n",
      "Epoch 147/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.3468 - val_accuracy: 1.0000 - val_loss: 0.3418 - learning_rate: 0.0010\n",
      "Epoch 148/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.3476 - val_accuracy: 1.0000 - val_loss: 0.3410 - learning_rate: 0.0010\n",
      "Epoch 149/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.3457 - val_accuracy: 1.0000 - val_loss: 0.3401 - learning_rate: 0.0010\n",
      "Epoch 150/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9968 - loss: 0.3545 - val_accuracy: 1.0000 - val_loss: 0.3392 - learning_rate: 0.0010\n",
      "Epoch 151/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.3482 - val_accuracy: 1.0000 - val_loss: 0.3383 - learning_rate: 0.0010\n",
      "Epoch 152/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.3484 - val_accuracy: 1.0000 - val_loss: 0.3374 - learning_rate: 0.0010\n",
      "Epoch 153/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.3463 - val_accuracy: 1.0000 - val_loss: 0.3365 - learning_rate: 0.0010\n",
      "Epoch 154/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.3508 - val_accuracy: 1.0000 - val_loss: 0.3357 - learning_rate: 0.0010\n",
      "Epoch 155/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.3486 - val_accuracy: 1.0000 - val_loss: 0.3348 - learning_rate: 0.0010\n",
      "Epoch 156/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9968 - loss: 0.3456 - val_accuracy: 1.0000 - val_loss: 0.3340 - learning_rate: 0.0010\n",
      "Epoch 157/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.3450 - val_accuracy: 1.0000 - val_loss: 0.3331 - learning_rate: 0.0010\n",
      "Epoch 158/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.3477 - val_accuracy: 1.0000 - val_loss: 0.3323 - learning_rate: 0.0010\n",
      "Epoch 159/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9936 - loss: 0.3592 - val_accuracy: 1.0000 - val_loss: 0.3314 - learning_rate: 0.0010\n",
      "Epoch 160/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9845 - loss: 0.3812 - val_accuracy: 1.0000 - val_loss: 0.3307 - learning_rate: 0.0010\n",
      "Epoch 161/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.3388 - val_accuracy: 1.0000 - val_loss: 0.3303 - learning_rate: 0.0010\n",
      "Epoch 162/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.3432 - val_accuracy: 1.0000 - val_loss: 0.3314 - learning_rate: 0.0010\n",
      "Epoch 163/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.3433 - val_accuracy: 1.0000 - val_loss: 0.3318 - learning_rate: 0.0010\n",
      "Epoch 164/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9877 - loss: 0.3800 - val_accuracy: 1.0000 - val_loss: 0.3284 - learning_rate: 0.0010\n",
      "Epoch 165/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.3396 - val_accuracy: 1.0000 - val_loss: 0.3274 - learning_rate: 0.0010\n",
      "Epoch 166/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.3406 - val_accuracy: 1.0000 - val_loss: 0.3265 - learning_rate: 0.0010\n",
      "Epoch 167/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9858 - loss: 0.3727 - val_accuracy: 1.0000 - val_loss: 0.3257 - learning_rate: 0.0010\n",
      "Epoch 168/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.3334 - val_accuracy: 1.0000 - val_loss: 0.3250 - learning_rate: 0.0010\n",
      "Epoch 169/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.3358 - val_accuracy: 1.0000 - val_loss: 0.3244 - learning_rate: 0.0010\n",
      "Epoch 170/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.3312 - val_accuracy: 1.0000 - val_loss: 0.3236 - learning_rate: 0.0010\n",
      "Epoch 171/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.3322 - val_accuracy: 1.0000 - val_loss: 0.3226 - learning_rate: 0.0010\n",
      "Epoch 172/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.3324 - val_accuracy: 1.0000 - val_loss: 0.3217 - learning_rate: 0.0010\n",
      "Epoch 173/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9909 - loss: 0.3500 - val_accuracy: 1.0000 - val_loss: 0.3209 - learning_rate: 0.0010\n",
      "Epoch 174/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.3299 - val_accuracy: 1.0000 - val_loss: 0.3200 - learning_rate: 0.0010\n",
      "Epoch 175/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.3257 - val_accuracy: 1.0000 - val_loss: 0.3192 - learning_rate: 0.0010\n",
      "Epoch 176/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 1.0000 - loss: 0.3290 - val_accuracy: 1.0000 - val_loss: 0.3183 - learning_rate: 0.0010\n",
      "Epoch 177/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.3241 - val_accuracy: 1.0000 - val_loss: 0.3175 - learning_rate: 0.0010\n",
      "Epoch 178/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.3232 - val_accuracy: 1.0000 - val_loss: 0.3166 - learning_rate: 0.0010\n",
      "Epoch 179/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.3316 - val_accuracy: 1.0000 - val_loss: 0.3158 - learning_rate: 0.0010\n",
      "Epoch 180/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.3198 - val_accuracy: 1.0000 - val_loss: 0.3150 - learning_rate: 0.0010\n",
      "Epoch 181/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9909 - loss: 0.3335 - val_accuracy: 1.0000 - val_loss: 0.3142 - learning_rate: 0.0010\n",
      "Epoch 182/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.3192 - val_accuracy: 1.0000 - val_loss: 0.3134 - learning_rate: 0.0010\n",
      "Epoch 183/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.3182 - val_accuracy: 1.0000 - val_loss: 0.3126 - learning_rate: 0.0010\n",
      "Epoch 184/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.3186 - val_accuracy: 1.0000 - val_loss: 0.3117 - learning_rate: 0.0010\n",
      "Epoch 185/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.3156 - val_accuracy: 1.0000 - val_loss: 0.3107 - learning_rate: 0.0010\n",
      "Epoch 186/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9948 - loss: 0.3278 - val_accuracy: 1.0000 - val_loss: 0.3099 - learning_rate: 0.0010\n",
      "Epoch 187/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.3162 - val_accuracy: 1.0000 - val_loss: 0.3090 - learning_rate: 0.0010\n",
      "Epoch 188/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.3123 - val_accuracy: 1.0000 - val_loss: 0.3082 - learning_rate: 0.0010\n",
      "Epoch 189/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.3130 - val_accuracy: 1.0000 - val_loss: 0.3073 - learning_rate: 0.0010\n",
      "Epoch 190/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 1.0000 - loss: 0.3124 - val_accuracy: 1.0000 - val_loss: 0.3065 - learning_rate: 0.0010\n",
      "Epoch 191/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.3089 - val_accuracy: 1.0000 - val_loss: 0.3056 - learning_rate: 0.0010\n",
      "Epoch 192/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.3079 - val_accuracy: 1.0000 - val_loss: 0.3047 - learning_rate: 0.0010\n",
      "Epoch 193/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.3088 - val_accuracy: 1.0000 - val_loss: 0.3039 - learning_rate: 0.0010\n",
      "Epoch 194/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.3093 - val_accuracy: 1.0000 - val_loss: 0.3030 - learning_rate: 0.0010\n",
      "Epoch 195/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.3073 - val_accuracy: 1.0000 - val_loss: 0.3021 - learning_rate: 0.0010\n",
      "Epoch 196/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.3061 - val_accuracy: 1.0000 - val_loss: 0.3013 - learning_rate: 0.0010\n",
      "Epoch 197/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.3043 - val_accuracy: 1.0000 - val_loss: 0.3004 - learning_rate: 0.0010\n",
      "Epoch 198/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.3039 - val_accuracy: 1.0000 - val_loss: 0.2996 - learning_rate: 0.0010\n",
      "Epoch 199/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.3062 - val_accuracy: 1.0000 - val_loss: 0.2987 - learning_rate: 0.0010\n",
      "Epoch 200/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.3058 - val_accuracy: 1.0000 - val_loss: 0.2978 - learning_rate: 0.0010\n",
      "Epoch 201/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.3016 - val_accuracy: 1.0000 - val_loss: 0.2970 - learning_rate: 0.0010\n",
      "Epoch 202/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.3040 - val_accuracy: 1.0000 - val_loss: 0.2961 - learning_rate: 0.0010\n",
      "Epoch 203/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.3064 - val_accuracy: 1.0000 - val_loss: 0.2953 - learning_rate: 0.0010\n",
      "Epoch 204/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.3016 - val_accuracy: 1.0000 - val_loss: 0.2944 - learning_rate: 0.0010\n",
      "Epoch 205/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.2986 - val_accuracy: 1.0000 - val_loss: 0.2936 - learning_rate: 0.0010\n",
      "Epoch 206/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2988 - val_accuracy: 1.0000 - val_loss: 0.2928 - learning_rate: 0.0010\n",
      "Epoch 207/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2982 - val_accuracy: 1.0000 - val_loss: 0.2919 - learning_rate: 0.0010\n",
      "Epoch 208/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9968 - loss: 0.3025 - val_accuracy: 1.0000 - val_loss: 0.2911 - learning_rate: 0.0010\n",
      "Epoch 209/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9909 - loss: 0.3142 - val_accuracy: 1.0000 - val_loss: 0.2903 - learning_rate: 0.0010\n",
      "Epoch 210/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.2949 - val_accuracy: 1.0000 - val_loss: 0.2896 - learning_rate: 0.0010\n",
      "Epoch 211/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.2955 - val_accuracy: 1.0000 - val_loss: 0.2889 - learning_rate: 0.0010\n",
      "Epoch 212/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.2978 - val_accuracy: 1.0000 - val_loss: 0.2882 - learning_rate: 0.0010\n",
      "Epoch 213/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9968 - loss: 0.2945 - val_accuracy: 1.0000 - val_loss: 0.2872 - learning_rate: 0.0010\n",
      "Epoch 214/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.2902 - val_accuracy: 1.0000 - val_loss: 0.2865 - learning_rate: 0.0010\n",
      "Epoch 215/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.2914 - val_accuracy: 1.0000 - val_loss: 0.2858 - learning_rate: 0.0010\n",
      "Epoch 216/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9948 - loss: 0.3196 - val_accuracy: 1.0000 - val_loss: 0.2849 - learning_rate: 0.0010\n",
      "Epoch 217/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.2995 - val_accuracy: 1.0000 - val_loss: 0.2841 - learning_rate: 0.0010\n",
      "Epoch 218/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.2961 - val_accuracy: 1.0000 - val_loss: 0.2833 - learning_rate: 0.0010\n",
      "Epoch 219/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2880 - val_accuracy: 1.0000 - val_loss: 0.2826 - learning_rate: 0.0010\n",
      "Epoch 220/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2897 - val_accuracy: 1.0000 - val_loss: 0.2820 - learning_rate: 0.0010\n",
      "Epoch 221/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9909 - loss: 0.3009 - val_accuracy: 1.0000 - val_loss: 0.2810 - learning_rate: 0.0010\n",
      "Epoch 222/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9916 - loss: 0.3016 - val_accuracy: 1.0000 - val_loss: 0.2802 - learning_rate: 0.0010\n",
      "Epoch 223/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9909 - loss: 0.3131 - val_accuracy: 1.0000 - val_loss: 0.2795 - learning_rate: 0.0010\n",
      "Epoch 224/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2819 - val_accuracy: 1.0000 - val_loss: 0.2787 - learning_rate: 0.0010\n",
      "Epoch 225/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.2831 - val_accuracy: 1.0000 - val_loss: 0.2780 - learning_rate: 0.0010\n",
      "Epoch 226/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.2853 - val_accuracy: 1.0000 - val_loss: 0.2772 - learning_rate: 0.0010\n",
      "Epoch 227/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2834 - val_accuracy: 1.0000 - val_loss: 0.2764 - learning_rate: 0.0010\n",
      "Epoch 228/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.2807 - val_accuracy: 1.0000 - val_loss: 0.2757 - learning_rate: 0.0010\n",
      "Epoch 229/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2807 - val_accuracy: 1.0000 - val_loss: 0.2749 - learning_rate: 0.0010\n",
      "Epoch 230/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.2799 - val_accuracy: 1.0000 - val_loss: 0.2741 - learning_rate: 0.0010\n",
      "Epoch 231/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9968 - loss: 0.2810 - val_accuracy: 1.0000 - val_loss: 0.2733 - learning_rate: 0.0010\n",
      "Epoch 232/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.2778 - val_accuracy: 1.0000 - val_loss: 0.2725 - learning_rate: 0.0010\n",
      "Epoch 233/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.2763 - val_accuracy: 1.0000 - val_loss: 0.2718 - learning_rate: 0.0010\n",
      "Epoch 234/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.2764 - val_accuracy: 1.0000 - val_loss: 0.2711 - learning_rate: 0.0010\n",
      "Epoch 235/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2739 - val_accuracy: 1.0000 - val_loss: 0.2703 - learning_rate: 0.0010\n",
      "Epoch 236/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2752 - val_accuracy: 1.0000 - val_loss: 0.2696 - learning_rate: 0.0010\n",
      "Epoch 237/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.2825 - val_accuracy: 1.0000 - val_loss: 0.2687 - learning_rate: 0.0010\n",
      "Epoch 238/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2733 - val_accuracy: 1.0000 - val_loss: 0.2680 - learning_rate: 0.0010\n",
      "Epoch 239/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2712 - val_accuracy: 1.0000 - val_loss: 0.2672 - learning_rate: 0.0010\n",
      "Epoch 240/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.2761 - val_accuracy: 1.0000 - val_loss: 0.2663 - learning_rate: 0.0010\n",
      "Epoch 241/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2710 - val_accuracy: 1.0000 - val_loss: 0.2655 - learning_rate: 0.0010\n",
      "Epoch 242/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2674 - val_accuracy: 1.0000 - val_loss: 0.2647 - learning_rate: 0.0010\n",
      "Epoch 243/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.2726 - val_accuracy: 1.0000 - val_loss: 0.2638 - learning_rate: 0.0010\n",
      "Epoch 244/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.2665 - val_accuracy: 1.0000 - val_loss: 0.2630 - learning_rate: 0.0010\n",
      "Epoch 245/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2697 - val_accuracy: 1.0000 - val_loss: 0.2622 - learning_rate: 0.0010\n",
      "Epoch 246/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.2674 - val_accuracy: 1.0000 - val_loss: 0.2614 - learning_rate: 0.0010\n",
      "Epoch 247/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.2668 - val_accuracy: 1.0000 - val_loss: 0.2606 - learning_rate: 0.0010\n",
      "Epoch 248/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.2629 - val_accuracy: 1.0000 - val_loss: 0.2598 - learning_rate: 0.0010\n",
      "Epoch 249/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.2636 - val_accuracy: 1.0000 - val_loss: 0.2590 - learning_rate: 0.0010\n",
      "Epoch 250/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.2651 - val_accuracy: 1.0000 - val_loss: 0.2581 - learning_rate: 0.0010\n",
      "Epoch 251/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.2619 - val_accuracy: 1.0000 - val_loss: 0.2573 - learning_rate: 0.0010\n",
      "Epoch 252/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.2612 - val_accuracy: 1.0000 - val_loss: 0.2565 - learning_rate: 0.0010\n",
      "Epoch 253/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.2610 - val_accuracy: 1.0000 - val_loss: 0.2557 - learning_rate: 0.0010\n",
      "Epoch 254/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.2578 - val_accuracy: 1.0000 - val_loss: 0.2549 - learning_rate: 0.0010\n",
      "Epoch 255/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.2569 - val_accuracy: 1.0000 - val_loss: 0.2540 - learning_rate: 0.0010\n",
      "Epoch 256/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.2579 - val_accuracy: 1.0000 - val_loss: 0.2532 - learning_rate: 0.0010\n",
      "Epoch 257/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.2585 - val_accuracy: 1.0000 - val_loss: 0.2524 - learning_rate: 0.0010\n",
      "Epoch 258/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.2549 - val_accuracy: 1.0000 - val_loss: 0.2516 - learning_rate: 0.0010\n",
      "Epoch 259/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.2537 - val_accuracy: 1.0000 - val_loss: 0.2508 - learning_rate: 0.0010\n",
      "Epoch 260/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2530 - val_accuracy: 1.0000 - val_loss: 0.2500 - learning_rate: 0.0010\n",
      "Epoch 261/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.2521 - val_accuracy: 1.0000 - val_loss: 0.2492 - learning_rate: 0.0010\n",
      "Epoch 262/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.2534 - val_accuracy: 1.0000 - val_loss: 0.2484 - learning_rate: 0.0010\n",
      "Epoch 263/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.2527 - val_accuracy: 1.0000 - val_loss: 0.2475 - learning_rate: 0.0010\n",
      "Epoch 264/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2560 - val_accuracy: 1.0000 - val_loss: 0.2467 - learning_rate: 0.0010\n",
      "Epoch 265/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9968 - loss: 0.2558 - val_accuracy: 1.0000 - val_loss: 0.2460 - learning_rate: 0.0010\n",
      "Epoch 266/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2497 - val_accuracy: 1.0000 - val_loss: 0.2454 - learning_rate: 0.0010\n",
      "Epoch 267/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9909 - loss: 0.2536 - val_accuracy: 1.0000 - val_loss: 0.2451 - learning_rate: 0.0010\n",
      "Epoch 268/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9909 - loss: 0.2528 - val_accuracy: 1.0000 - val_loss: 0.2440 - learning_rate: 0.0010\n",
      "Epoch 269/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2475 - val_accuracy: 1.0000 - val_loss: 0.2431 - learning_rate: 0.0010\n",
      "Epoch 270/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2451 - val_accuracy: 1.0000 - val_loss: 0.2422 - learning_rate: 0.0010\n",
      "Epoch 271/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.2442 - val_accuracy: 1.0000 - val_loss: 0.2415 - learning_rate: 0.0010\n",
      "Epoch 272/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.2438 - val_accuracy: 1.0000 - val_loss: 0.2407 - learning_rate: 0.0010\n",
      "Epoch 273/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.2453 - val_accuracy: 1.0000 - val_loss: 0.2399 - learning_rate: 0.0010\n",
      "Epoch 274/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.2433 - val_accuracy: 1.0000 - val_loss: 0.2391 - learning_rate: 0.0010\n",
      "Epoch 275/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2438 - val_accuracy: 1.0000 - val_loss: 0.2383 - learning_rate: 0.0010\n",
      "Epoch 276/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9968 - loss: 0.2432 - val_accuracy: 1.0000 - val_loss: 0.2375 - learning_rate: 0.0010\n",
      "Epoch 277/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2392 - val_accuracy: 1.0000 - val_loss: 0.2368 - learning_rate: 0.0010\n",
      "Epoch 278/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9948 - loss: 0.2475 - val_accuracy: 1.0000 - val_loss: 0.2360 - learning_rate: 0.0010\n",
      "Epoch 279/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9909 - loss: 0.2873 - val_accuracy: 1.0000 - val_loss: 0.2353 - learning_rate: 0.0010\n",
      "Epoch 280/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2387 - val_accuracy: 1.0000 - val_loss: 0.2346 - learning_rate: 0.0010\n",
      "Epoch 281/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2434 - val_accuracy: 1.0000 - val_loss: 0.2339 - learning_rate: 0.0010\n",
      "Epoch 282/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2377 - val_accuracy: 1.0000 - val_loss: 0.2332 - learning_rate: 0.0010\n",
      "Epoch 283/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.2453 - val_accuracy: 1.0000 - val_loss: 0.2325 - learning_rate: 0.0010\n",
      "Epoch 284/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2379 - val_accuracy: 1.0000 - val_loss: 0.2318 - learning_rate: 0.0010\n",
      "Epoch 285/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.2338 - val_accuracy: 1.0000 - val_loss: 0.2310 - learning_rate: 0.0010\n",
      "Epoch 286/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.2351 - val_accuracy: 1.0000 - val_loss: 0.2302 - learning_rate: 0.0010\n",
      "Epoch 287/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2350 - val_accuracy: 1.0000 - val_loss: 0.2294 - learning_rate: 0.0010\n",
      "Epoch 288/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.2330 - val_accuracy: 1.0000 - val_loss: 0.2287 - learning_rate: 0.0010\n",
      "Epoch 289/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2318 - val_accuracy: 1.0000 - val_loss: 0.2279 - learning_rate: 0.0010\n",
      "Epoch 290/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2303 - val_accuracy: 1.0000 - val_loss: 0.2271 - learning_rate: 0.0010\n",
      "Epoch 291/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.2329 - val_accuracy: 1.0000 - val_loss: 0.2263 - learning_rate: 0.0010\n",
      "Epoch 292/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2310 - val_accuracy: 1.0000 - val_loss: 0.2255 - learning_rate: 0.0010\n",
      "Epoch 293/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2276 - val_accuracy: 1.0000 - val_loss: 0.2248 - learning_rate: 0.0010\n",
      "Epoch 294/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2267 - val_accuracy: 1.0000 - val_loss: 0.2240 - learning_rate: 0.0010\n",
      "Epoch 295/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.2270 - val_accuracy: 1.0000 - val_loss: 0.2232 - learning_rate: 0.0010\n",
      "Epoch 296/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.2262 - val_accuracy: 1.0000 - val_loss: 0.2224 - learning_rate: 0.0010\n",
      "Epoch 297/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2268 - val_accuracy: 1.0000 - val_loss: 0.2217 - learning_rate: 0.0010\n",
      "Epoch 298/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2237 - val_accuracy: 1.0000 - val_loss: 0.2209 - learning_rate: 0.0010\n",
      "Epoch 299/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.2224 - val_accuracy: 1.0000 - val_loss: 0.2201 - learning_rate: 0.0010\n",
      "Epoch 300/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.2247 - val_accuracy: 1.0000 - val_loss: 0.2194 - learning_rate: 0.0010\n",
      "Epoch 301/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2245 - val_accuracy: 1.0000 - val_loss: 0.2186 - learning_rate: 0.0010\n",
      "Epoch 302/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.2201 - val_accuracy: 1.0000 - val_loss: 0.2179 - learning_rate: 0.0010\n",
      "Epoch 303/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.2197 - val_accuracy: 1.0000 - val_loss: 0.2171 - learning_rate: 0.0010\n",
      "Epoch 304/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2187 - val_accuracy: 1.0000 - val_loss: 0.2164 - learning_rate: 0.0010\n",
      "Epoch 305/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2202 - val_accuracy: 1.0000 - val_loss: 0.2156 - learning_rate: 0.0010\n",
      "Epoch 306/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2198 - val_accuracy: 1.0000 - val_loss: 0.2149 - learning_rate: 0.0010\n",
      "Epoch 307/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2163 - val_accuracy: 1.0000 - val_loss: 0.2141 - learning_rate: 0.0010\n",
      "Epoch 308/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.2188 - val_accuracy: 1.0000 - val_loss: 0.2134 - learning_rate: 0.0010\n",
      "Epoch 309/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2172 - val_accuracy: 1.0000 - val_loss: 0.2126 - learning_rate: 0.0010\n",
      "Epoch 310/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.2160 - val_accuracy: 1.0000 - val_loss: 0.2118 - learning_rate: 0.0010\n",
      "Epoch 311/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9968 - loss: 0.2197 - val_accuracy: 1.0000 - val_loss: 0.2111 - learning_rate: 0.0010\n",
      "Epoch 312/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.2131 - val_accuracy: 1.0000 - val_loss: 0.2104 - learning_rate: 0.0010\n",
      "Epoch 313/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2131 - val_accuracy: 1.0000 - val_loss: 0.2098 - learning_rate: 0.0010\n",
      "Epoch 314/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2148 - val_accuracy: 1.0000 - val_loss: 0.2092 - learning_rate: 0.0010\n",
      "Epoch 315/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2105 - val_accuracy: 1.0000 - val_loss: 0.2085 - learning_rate: 0.0010\n",
      "Epoch 316/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9968 - loss: 0.2127 - val_accuracy: 1.0000 - val_loss: 0.2078 - learning_rate: 0.0010\n",
      "Epoch 317/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2101 - val_accuracy: 1.0000 - val_loss: 0.2071 - learning_rate: 0.0010\n",
      "Epoch 318/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2094 - val_accuracy: 1.0000 - val_loss: 0.2065 - learning_rate: 0.0010\n",
      "Epoch 319/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2132 - val_accuracy: 1.0000 - val_loss: 0.2058 - learning_rate: 0.0010\n",
      "Epoch 320/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9909 - loss: 0.2166 - val_accuracy: 1.0000 - val_loss: 0.2051 - learning_rate: 0.0010\n",
      "Epoch 321/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9909 - loss: 0.2164 - val_accuracy: 1.0000 - val_loss: 0.2045 - learning_rate: 0.0010\n",
      "Epoch 322/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2102 - val_accuracy: 1.0000 - val_loss: 0.2038 - learning_rate: 0.0010\n",
      "Epoch 323/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.2062 - val_accuracy: 1.0000 - val_loss: 0.2032 - learning_rate: 0.0010\n",
      "Epoch 324/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.2069 - val_accuracy: 1.0000 - val_loss: 0.2025 - learning_rate: 0.0010\n",
      "Epoch 325/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2048 - val_accuracy: 1.0000 - val_loss: 0.2018 - learning_rate: 0.0010\n",
      "Epoch 326/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.2049 - val_accuracy: 1.0000 - val_loss: 0.2012 - learning_rate: 0.0010\n",
      "Epoch 327/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2027 - val_accuracy: 1.0000 - val_loss: 0.2005 - learning_rate: 0.0010\n",
      "Epoch 328/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.2110 - val_accuracy: 1.0000 - val_loss: 0.1998 - learning_rate: 0.0010\n",
      "Epoch 329/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.2025 - val_accuracy: 1.0000 - val_loss: 0.1991 - learning_rate: 0.0010\n",
      "Epoch 330/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.2012 - val_accuracy: 1.0000 - val_loss: 0.1984 - learning_rate: 0.0010\n",
      "Epoch 331/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.2018 - val_accuracy: 1.0000 - val_loss: 0.1977 - learning_rate: 0.0010\n",
      "Epoch 332/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.2013 - val_accuracy: 1.0000 - val_loss: 0.1970 - learning_rate: 0.0010\n",
      "Epoch 333/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2008 - val_accuracy: 1.0000 - val_loss: 0.1963 - learning_rate: 0.0010\n",
      "Epoch 334/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1988 - val_accuracy: 1.0000 - val_loss: 0.1955 - learning_rate: 0.0010\n",
      "Epoch 335/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1969 - val_accuracy: 1.0000 - val_loss: 0.1948 - learning_rate: 0.0010\n",
      "Epoch 336/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1964 - val_accuracy: 1.0000 - val_loss: 0.1941 - learning_rate: 0.0010\n",
      "Epoch 337/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.1975 - val_accuracy: 1.0000 - val_loss: 0.1934 - learning_rate: 0.0010\n",
      "Epoch 338/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.1975 - val_accuracy: 1.0000 - val_loss: 0.1927 - learning_rate: 0.0010\n",
      "Epoch 339/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1952 - val_accuracy: 1.0000 - val_loss: 0.1920 - learning_rate: 0.0010\n",
      "Epoch 340/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.1928 - val_accuracy: 1.0000 - val_loss: 0.1913 - learning_rate: 0.0010\n",
      "Epoch 341/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1941 - val_accuracy: 1.0000 - val_loss: 0.1906 - learning_rate: 0.0010\n",
      "Epoch 342/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1923 - val_accuracy: 1.0000 - val_loss: 0.1899 - learning_rate: 0.0010\n",
      "Epoch 343/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1906 - val_accuracy: 1.0000 - val_loss: 0.1891 - learning_rate: 0.0010\n",
      "Epoch 344/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1918 - val_accuracy: 1.0000 - val_loss: 0.1884 - learning_rate: 0.0010\n",
      "Epoch 345/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1896 - val_accuracy: 1.0000 - val_loss: 0.1877 - learning_rate: 0.0010\n",
      "Epoch 346/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1916 - val_accuracy: 1.0000 - val_loss: 0.1870 - learning_rate: 0.0010\n",
      "Epoch 347/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1882 - val_accuracy: 1.0000 - val_loss: 0.1863 - learning_rate: 0.0010\n",
      "Epoch 348/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1931 - val_accuracy: 1.0000 - val_loss: 0.1856 - learning_rate: 0.0010\n",
      "Epoch 349/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1899 - val_accuracy: 1.0000 - val_loss: 0.1850 - learning_rate: 0.0010\n",
      "Epoch 350/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1855 - val_accuracy: 1.0000 - val_loss: 0.1844 - learning_rate: 0.0010\n",
      "Epoch 351/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.1883 - val_accuracy: 1.0000 - val_loss: 0.1839 - learning_rate: 0.0010\n",
      "Epoch 352/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.1861 - val_accuracy: 1.0000 - val_loss: 0.1833 - learning_rate: 0.0010\n",
      "Epoch 353/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9909 - loss: 0.1942 - val_accuracy: 1.0000 - val_loss: 0.1826 - learning_rate: 0.0010\n",
      "Epoch 354/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9968 - loss: 0.1931 - val_accuracy: 1.0000 - val_loss: 0.1820 - learning_rate: 0.0010\n",
      "Epoch 355/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.1864 - val_accuracy: 1.0000 - val_loss: 0.1816 - learning_rate: 0.0010\n",
      "Epoch 356/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9877 - loss: 0.2179 - val_accuracy: 1.0000 - val_loss: 0.1813 - learning_rate: 0.0010\n",
      "Epoch 357/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1850 - val_accuracy: 1.0000 - val_loss: 0.1810 - learning_rate: 0.0010\n",
      "Epoch 358/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9897 - loss: 0.2082 - val_accuracy: 1.0000 - val_loss: 0.1809 - learning_rate: 0.0010\n",
      "Epoch 359/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9787 - loss: 0.2229 - val_accuracy: 1.0000 - val_loss: 0.1808 - learning_rate: 0.0010\n",
      "Epoch 360/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1926 - val_accuracy: 0.9750 - val_loss: 0.2263 - learning_rate: 0.0010\n",
      "Epoch 361/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9586 - loss: 0.2888 - val_accuracy: 1.0000 - val_loss: 0.1810 - learning_rate: 0.0010\n",
      "Epoch 362/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9877 - loss: 0.2294 - val_accuracy: 1.0000 - val_loss: 0.1806 - learning_rate: 0.0010\n",
      "Epoch 363/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.2026 - val_accuracy: 1.0000 - val_loss: 0.1807 - learning_rate: 0.0010\n",
      "Epoch 364/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2011 - val_accuracy: 1.0000 - val_loss: 0.1806 - learning_rate: 0.0010\n",
      "Epoch 365/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9916 - loss: 0.2152 - val_accuracy: 1.0000 - val_loss: 0.1806 - learning_rate: 0.0010\n",
      "Epoch 366/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9845 - loss: 0.2119 - val_accuracy: 1.0000 - val_loss: 0.1815 - learning_rate: 0.0010\n",
      "Epoch 367/500\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9844 - loss: 0.2223\n",
      "Epoch 367: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9858 - loss: 0.2195 - val_accuracy: 1.0000 - val_loss: 0.1822 - learning_rate: 0.0010\n",
      "Epoch 368/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9909 - loss: 0.2208 - val_accuracy: 1.0000 - val_loss: 0.1817 - learning_rate: 2.0000e-04\n",
      "Epoch 369/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1907 - val_accuracy: 1.0000 - val_loss: 0.1814 - learning_rate: 2.0000e-04\n",
      "Epoch 370/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9858 - loss: 0.2027 - val_accuracy: 1.0000 - val_loss: 0.1811 - learning_rate: 2.0000e-04\n",
      "Epoch 371/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9819 - loss: 0.2126 - val_accuracy: 1.0000 - val_loss: 0.1809 - learning_rate: 2.0000e-04\n",
      "Epoch 372/500\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1997\n",
      "Epoch 372: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.1948 - val_accuracy: 1.0000 - val_loss: 0.1807 - learning_rate: 2.0000e-04\n",
      "Epoch 373/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.1889 - val_accuracy: 1.0000 - val_loss: 0.1807 - learning_rate: 4.0000e-05\n",
      "Epoch 374/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9936 - loss: 0.1948 - val_accuracy: 1.0000 - val_loss: 0.1807 - learning_rate: 4.0000e-05\n",
      "Epoch 375/500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.1853 - val_accuracy: 1.0000 - val_loss: 0.1806 - learning_rate: 4.0000e-05\n",
      "Epoch 375: early stopping\n",
      "Restoring model weights from the end of the best epoch: 365.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            cough       1.00      1.00      1.00         5\n",
      "          falling       1.00      1.00      1.00         3\n",
      "         headache       1.00      1.00      1.00        12\n",
      "     heart stroke       1.00      1.00      1.00         7\n",
      "          sitting       1.00      1.00      1.00        10\n",
      "         standing       1.00      1.00      1.00         6\n",
      "standing normally       1.00      1.00      1.00         6\n",
      "\n",
      "         accuracy                           1.00        49\n",
      "        macro avg       1.00      1.00      1.00        49\n",
      "     weighted avg       1.00      1.00      1.00        49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and preprocessing artifacts saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('pose_data.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop(columns=['Label'])\n",
    "y = data['Label']\n",
    "\n",
    "# Encode labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Save label encoder for future use\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# One-hot encode the labels for deep learning\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Train-test split (using stratify for balanced classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_one_hot, test_size=0.2, random_state=42, stratify=y_one_hot\n",
    ")\n",
    "\n",
    "# Build the deep learning model\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.001), input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(y_one_hot.shape[1], activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks for learning rate adjustment and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=500,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[reduce_lr, early_stop]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot encoded test labels back to integers\n",
    "\n",
    "# Classification report\n",
    "labels = np.unique(y_test_labels)\n",
    "print(\"Classification Report:\\n\", classification_report(\n",
    "    y_test_labels,\n",
    "    y_pred,\n",
    "    labels=labels,\n",
    "    target_names=label_encoder.inverse_transform(labels)\n",
    "))\n",
    "\n",
    "# Save the trained model\n",
    "model.save('activity_classifier_optimized.h5')\n",
    "\n",
    "print(\"Model and preprocessing artifacts saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cam TEst 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model, scaler, and label encoder\n",
    "model = tf.keras.models.load_model('activity_classifier_optimized.h5')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Initialize Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to preprocess pose landmarks\n",
    "def preprocess_landmarks(landmarks):\n",
    "    try:\n",
    "        feature_vector = [\n",
    "            [landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in landmarks\n",
    "        ]\n",
    "        feature_vector = np.array(feature_vector).flatten().reshape(1, -1)\n",
    "        feature_vector = scaler.transform(feature_vector)  # Standardize the feature vector\n",
    "        return feature_vector\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to predict activity from processed landmarks\n",
    "def predict_activity(processed_landmarks):\n",
    "    try:\n",
    "        predictions = model.predict(processed_landmarks)\n",
    "        predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "        return label_encoder.inverse_transform([predicted_class])[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return \"Prediction Error\"\n",
    "\n",
    "# Start webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Mediapipe Pose estimation\n",
    "with mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No frame received from webcam. Exiting.\")\n",
    "            break\n",
    "\n",
    "        # Convert image to RGB for Mediapipe\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose landmarks\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR for OpenCV display\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # If pose landmarks are detected\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Preprocess landmarks and predict activity\n",
    "            processed_landmarks = preprocess_landmarks(landmarks)\n",
    "            activity = (\n",
    "                predict_activity(processed_landmarks)\n",
    "                if processed_landmarks is not None\n",
    "                else \"Processing Error\"\n",
    "            )\n",
    "        else:\n",
    "            activity = \"No Person Detected\"\n",
    "\n",
    "        # Display the activity label on the video feed\n",
    "        cv2.putText(image, f\"Activity: {activity}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the video feed\n",
    "        cv2.imshow('Real-time Activity Detection', image)\n",
    "\n",
    "        # Quit with 'q' key\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            print(\"Exiting application.\")\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('pose_data.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop(columns=['Label'])\n",
    "y = data['Label']\n",
    "\n",
    "# Encode labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Save label encoder for future use\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# One-hot encode the labels for deep learning\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Train-test split (using stratify for balanced classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_one_hot, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Build the deep learning model\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.001), input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(y_one_hot.shape[1], activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks for learning rate adjustment and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[reduce_lr, early_stop]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot encoded test labels back to integers\n",
    "\n",
    "# Classification report\n",
    "labels = np.unique(y_test_labels)\n",
    "print(\"Classification Report:\\n\", classification_report(\n",
    "    y_test_labels,\n",
    "    y_pred,\n",
    "    labels=labels,\n",
    "    target_names=label_encoder.inverse_transform(labels)\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_labels, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model\n",
    "model.save('activity_classifier_optimized.h5')\n",
    "\n",
    "print(\"Model and preprocessing artifacts saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cam test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import mediapipe as mp\n",
    "\n",
    "# Load the trained model, scaler, and label encoder\n",
    "model = tf.keras.models.load_model('activity_classifier_optimized.h5')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Initialize Mediapipe Pose for pose detection\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to preprocess pose landmarks\n",
    "def preprocess_landmarks(landmarks):\n",
    "    try:\n",
    "        # Extract features (x, y, z, visibility) for each landmark\n",
    "        feature_vector = [\n",
    "            [landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in landmarks\n",
    "        ]\n",
    "        feature_vector = np.array(feature_vector).flatten().reshape(1, -1)\n",
    "        feature_vector = scaler.transform(feature_vector)  # Standardize the feature vector\n",
    "        return feature_vector\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to predict activity from processed landmarks\n",
    "def predict_activity(processed_landmarks):\n",
    "    try:\n",
    "        predictions = model.predict(processed_landmarks)\n",
    "        predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "        return label_encoder.inverse_transform([predicted_class])[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return \"Prediction Error\"\n",
    "\n",
    "# Start webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Mediapipe Pose estimation\n",
    "with mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No frame received from webcam. Exiting.\")\n",
    "            break\n",
    "\n",
    "        # Convert image to RGB for Mediapipe\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose landmarks\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR for OpenCV display\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # If pose landmarks are detected\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Preprocess landmarks and predict activity\n",
    "            processed_landmarks = preprocess_landmarks(landmarks)\n",
    "            activity = (\n",
    "                predict_activity(processed_landmarks)\n",
    "                if processed_landmarks is not None\n",
    "                else \"Processing Error\"\n",
    "            )\n",
    "        else:\n",
    "            activity = \"No Person Detected\"\n",
    "\n",
    "        # Display the activity label on the video feed\n",
    "        cv2.putText(image, f\"Activity: {activity}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the video feed\n",
    "        cv2.imshow('Real-time Activity Detection', image)\n",
    "\n",
    "        # Quit with 'q' key\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            print(\"Exiting application.\")\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\anacondadata\\envs\\human\\lib\\site-packages (2.18.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\anacondadata\\envs\\human\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\anacondadata\\envs\\human\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\anacondadata\\envs\\human\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\anacondadata\\envs\\human\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anacondadata\\envs\\human\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - accuracy: 0.0848 - loss: 3.3573 - val_accuracy: 0.0779 - val_loss: 2.6649 - learning_rate: 5.0000e-04\n",
      "Epoch 2/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.1418 - loss: 3.4628 - val_accuracy: 0.1558 - val_loss: 2.5534 - learning_rate: 5.0000e-04\n",
      "Epoch 3/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.1427 - loss: 3.2217 - val_accuracy: 0.4675 - val_loss: 2.4501 - learning_rate: 5.0000e-04\n",
      "Epoch 4/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.1956 - loss: 2.6448 - val_accuracy: 0.5065 - val_loss: 2.3610 - learning_rate: 5.0000e-04\n",
      "Epoch 5/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2511 - loss: 2.6685 - val_accuracy: 0.5584 - val_loss: 2.2715 - learning_rate: 5.0000e-04\n",
      "Epoch 6/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3226 - loss: 2.3344 - val_accuracy: 0.5844 - val_loss: 2.1916 - learning_rate: 5.0000e-04\n",
      "Epoch 7/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3337 - loss: 2.3434 - val_accuracy: 0.6234 - val_loss: 2.1129 - learning_rate: 5.0000e-04\n",
      "Epoch 8/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3710 - loss: 2.1271 - val_accuracy: 0.6234 - val_loss: 2.0411 - learning_rate: 5.0000e-04\n",
      "Epoch 9/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4428 - loss: 2.0725 - val_accuracy: 0.6234 - val_loss: 1.9740 - learning_rate: 5.0000e-04\n",
      "Epoch 10/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5121 - loss: 2.0135 - val_accuracy: 0.6364 - val_loss: 1.9158 - learning_rate: 5.0000e-04\n",
      "Epoch 11/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4963 - loss: 1.9789 - val_accuracy: 0.6364 - val_loss: 1.8553 - learning_rate: 5.0000e-04\n",
      "Epoch 12/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4987 - loss: 1.8956 - val_accuracy: 0.6364 - val_loss: 1.7980 - learning_rate: 5.0000e-04\n",
      "Epoch 13/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4865 - loss: 1.8828 - val_accuracy: 0.6364 - val_loss: 1.7424 - learning_rate: 5.0000e-04\n",
      "Epoch 14/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6004 - loss: 1.6604 - val_accuracy: 0.6364 - val_loss: 1.6923 - learning_rate: 5.0000e-04\n",
      "Epoch 15/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5663 - loss: 1.6118 - val_accuracy: 0.6494 - val_loss: 1.6440 - learning_rate: 5.0000e-04\n",
      "Epoch 16/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5483 - loss: 1.7758 - val_accuracy: 0.6494 - val_loss: 1.5973 - learning_rate: 5.0000e-04\n",
      "Epoch 17/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5707 - loss: 1.5963 - val_accuracy: 0.6883 - val_loss: 1.5557 - learning_rate: 5.0000e-04\n",
      "Epoch 18/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6346 - loss: 1.5428 - val_accuracy: 0.6883 - val_loss: 1.5228 - learning_rate: 5.0000e-04\n",
      "Epoch 19/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6451 - loss: 1.5858 - val_accuracy: 0.7143 - val_loss: 1.4925 - learning_rate: 5.0000e-04\n",
      "Epoch 20/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6297 - loss: 1.4788 - val_accuracy: 0.7273 - val_loss: 1.4637 - learning_rate: 5.0000e-04\n",
      "Epoch 21/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6624 - loss: 1.4370 - val_accuracy: 0.7273 - val_loss: 1.4332 - learning_rate: 5.0000e-04\n",
      "Epoch 22/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7090 - loss: 1.4161 - val_accuracy: 0.7403 - val_loss: 1.3992 - learning_rate: 5.0000e-04\n",
      "Epoch 23/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6637 - loss: 1.4028 - val_accuracy: 0.7532 - val_loss: 1.3702 - learning_rate: 5.0000e-04\n",
      "Epoch 24/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7021 - loss: 1.3478 - val_accuracy: 0.7532 - val_loss: 1.3445 - learning_rate: 5.0000e-04\n",
      "Epoch 25/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7105 - loss: 1.2447 - val_accuracy: 0.7532 - val_loss: 1.3211 - learning_rate: 5.0000e-04\n",
      "Epoch 26/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7079 - loss: 1.3692 - val_accuracy: 0.7532 - val_loss: 1.3038 - learning_rate: 5.0000e-04\n",
      "Epoch 27/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6554 - loss: 1.4211 - val_accuracy: 0.7532 - val_loss: 1.2940 - learning_rate: 5.0000e-04\n",
      "Epoch 28/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7368 - loss: 1.2619 - val_accuracy: 0.7532 - val_loss: 1.2846 - learning_rate: 5.0000e-04\n",
      "Epoch 29/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7220 - loss: 1.2652 - val_accuracy: 0.7532 - val_loss: 1.2734 - learning_rate: 5.0000e-04\n",
      "Epoch 30/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7617 - loss: 1.2179 - val_accuracy: 0.7532 - val_loss: 1.2646 - learning_rate: 5.0000e-04\n",
      "Epoch 31/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7778 - loss: 1.2128 - val_accuracy: 0.7532 - val_loss: 1.2559 - learning_rate: 5.0000e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7519 - loss: 1.2078 - val_accuracy: 0.7403 - val_loss: 1.2446 - learning_rate: 5.0000e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7365 - loss: 1.2278 - val_accuracy: 0.7403 - val_loss: 1.2348 - learning_rate: 5.0000e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7838 - loss: 1.0880 - val_accuracy: 0.7403 - val_loss: 1.2266 - learning_rate: 5.0000e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7814 - loss: 1.1781 - val_accuracy: 0.7403 - val_loss: 1.2149 - learning_rate: 5.0000e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7977 - loss: 1.0932 - val_accuracy: 0.7403 - val_loss: 1.2057 - learning_rate: 5.0000e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7908 - loss: 1.1184 - val_accuracy: 0.7403 - val_loss: 1.1995 - learning_rate: 5.0000e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8138 - loss: 1.0818 - val_accuracy: 0.7403 - val_loss: 1.1876 - learning_rate: 5.0000e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7713 - loss: 1.0516 - val_accuracy: 0.7403 - val_loss: 1.1763 - learning_rate: 5.0000e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8124 - loss: 1.0836 - val_accuracy: 0.7403 - val_loss: 1.1699 - learning_rate: 5.0000e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8153 - loss: 0.9882 - val_accuracy: 0.7532 - val_loss: 1.1621 - learning_rate: 5.0000e-04\n",
      "Epoch 42/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7741 - loss: 1.0826 - val_accuracy: 0.7532 - val_loss: 1.1525 - learning_rate: 5.0000e-04\n",
      "Epoch 43/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7988 - loss: 1.0288 - val_accuracy: 0.7532 - val_loss: 1.1422 - learning_rate: 5.0000e-04\n",
      "Epoch 44/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7795 - loss: 1.0401 - val_accuracy: 0.7532 - val_loss: 1.1310 - learning_rate: 5.0000e-04\n",
      "Epoch 45/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8456 - loss: 0.9290 - val_accuracy: 0.7662 - val_loss: 1.1258 - learning_rate: 5.0000e-04\n",
      "Epoch 46/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8027 - loss: 1.0600 - val_accuracy: 0.7792 - val_loss: 1.1228 - learning_rate: 5.0000e-04\n",
      "Epoch 47/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8044 - loss: 1.0639 - val_accuracy: 0.7792 - val_loss: 1.1173 - learning_rate: 5.0000e-04\n",
      "Epoch 48/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8385 - loss: 0.9604 - val_accuracy: 0.7792 - val_loss: 1.1169 - learning_rate: 5.0000e-04\n",
      "Epoch 49/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8387 - loss: 0.8970 - val_accuracy: 0.7792 - val_loss: 1.1153 - learning_rate: 5.0000e-04\n",
      "Epoch 50/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8647 - loss: 0.8608 - val_accuracy: 0.7792 - val_loss: 1.1125 - learning_rate: 5.0000e-04\n",
      "Epoch 51/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8420 - loss: 0.9053 - val_accuracy: 0.7792 - val_loss: 1.1056 - learning_rate: 5.0000e-04\n",
      "Epoch 52/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8174 - loss: 0.9756 - val_accuracy: 0.7792 - val_loss: 1.0931 - learning_rate: 5.0000e-04\n",
      "Epoch 53/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8292 - loss: 0.9058 - val_accuracy: 0.7792 - val_loss: 1.0808 - learning_rate: 5.0000e-04\n",
      "Epoch 54/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8465 - loss: 0.9170 - val_accuracy: 0.7792 - val_loss: 1.0686 - learning_rate: 5.0000e-04\n",
      "Epoch 55/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7808 - loss: 0.9627 - val_accuracy: 0.8052 - val_loss: 1.0629 - learning_rate: 5.0000e-04\n",
      "Epoch 56/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8385 - loss: 0.9303 - val_accuracy: 0.8182 - val_loss: 1.0558 - learning_rate: 5.0000e-04\n",
      "Epoch 57/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8116 - loss: 0.9801 - val_accuracy: 0.8182 - val_loss: 1.0479 - learning_rate: 5.0000e-04\n",
      "Epoch 58/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8550 - loss: 0.8872 - val_accuracy: 0.8312 - val_loss: 1.0440 - learning_rate: 5.0000e-04\n",
      "Epoch 59/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8426 - loss: 0.8721 - val_accuracy: 0.8312 - val_loss: 1.0460 - learning_rate: 5.0000e-04\n",
      "Epoch 60/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8940 - loss: 0.8007 - val_accuracy: 0.8312 - val_loss: 1.0479 - learning_rate: 5.0000e-04\n",
      "Epoch 61/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8280 - loss: 0.9328 - val_accuracy: 0.8312 - val_loss: 1.0591 - learning_rate: 5.0000e-04\n",
      "Epoch 62/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8606 - loss: 0.8773 - val_accuracy: 0.8312 - val_loss: 1.0710 - learning_rate: 5.0000e-04\n",
      "Epoch 63/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8651 - loss: 0.8014\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8621 - loss: 0.8051 - val_accuracy: 0.8312 - val_loss: 1.0686 - learning_rate: 5.0000e-04\n",
      "Epoch 64/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8450 - loss: 0.8531 - val_accuracy: 0.8312 - val_loss: 1.0681 - learning_rate: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8760 - loss: 0.8161 - val_accuracy: 0.8312 - val_loss: 1.0674 - learning_rate: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8682 - loss: 0.8306 - val_accuracy: 0.8312 - val_loss: 1.0663 - learning_rate: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8452 - loss: 0.7983 - val_accuracy: 0.8312 - val_loss: 1.0661 - learning_rate: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8438 - loss: 0.8905\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8569 - loss: 0.8509 - val_accuracy: 0.8312 - val_loss: 1.0661 - learning_rate: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8946 - loss: 0.8217 - val_accuracy: 0.8312 - val_loss: 1.0661 - learning_rate: 2.0000e-05\n",
      "Epoch 70/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8473 - loss: 0.8573 - val_accuracy: 0.8312 - val_loss: 1.0659 - learning_rate: 2.0000e-05\n",
      "Epoch 71/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8816 - loss: 0.7929 - val_accuracy: 0.8312 - val_loss: 1.0665 - learning_rate: 2.0000e-05\n",
      "Epoch 72/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8742 - loss: 0.8445 - val_accuracy: 0.8312 - val_loss: 1.0661 - learning_rate: 2.0000e-05\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9219 - loss: 0.7303\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 4.000000262749381e-06.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8888 - loss: 0.8054 - val_accuracy: 0.8312 - val_loss: 1.0656 - learning_rate: 2.0000e-05\n",
      "Epoch 73: early stopping\n",
      "Restoring model weights from the end of the best epoch: 58.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anacondadata\\envs\\human\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\anacondadata\\envs\\human\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\anacondadata\\envs\\human\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "            cough       0.80      0.80      0.80         5\n",
      "         coughing       0.00      0.00      0.00         7\n",
      "          falling       0.89      0.62      0.73        13\n",
      "         headache       0.77      0.96      0.86        25\n",
      "     heart stroke       0.73      0.69      0.71        16\n",
      "      heartstroke       0.00      0.00      0.00         1\n",
      "          sitting       0.67      0.93      0.78        15\n",
      "         standing       1.00      0.89      0.94         9\n",
      "standing normally       1.00      1.00      1.00         6\n",
      "\n",
      "         accuracy                           0.77        97\n",
      "        macro avg       0.65      0.65      0.65        97\n",
      "     weighted avg       0.74      0.77      0.75        97\n",
      "\n",
      "Model and preprocessing artifacts saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('pose_data.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop(columns=['Label'])\n",
    "y = data['Label']\n",
    "\n",
    "# Encode labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Save label encoder for future use\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# One-hot encode the labels for deep learning\n",
    "y_one_hot = to_categorical(y_encoded)\n",
    "\n",
    "# Train-test split (using stratify for balanced classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_one_hot, test_size=0.2, random_state=42, stratify=y_one_hot\n",
    ")\n",
    "\n",
    "# Build the deep learning model with improved architecture\n",
    "model = Sequential([    \n",
    "    Dense(512, activation='relu', kernel_regularizer=l2(0.0005), input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.0005)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.0005)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    \n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.0005)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(y_one_hot.shape[1], activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),  # Lower learning rate for more stability\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks for learning rate adjustment and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)  # Longer patience\n",
    "\n",
    "# Train the model with additional steps\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=1000,  # Increased epochs to allow for more training time\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[reduce_lr, early_stop],\n",
    "    shuffle=True  # Shuffle data during training\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)  # Convert one-hot encoded test labels back to integers\n",
    "\n",
    "# Classification report\n",
    "labels = np.unique(y_test_labels)\n",
    "print(\"Classification Report:\\n\", classification_report(\n",
    "    y_test_labels,\n",
    "    y_pred,\n",
    "    labels=labels,\n",
    "    target_names=label_encoder.inverse_transform(labels)\n",
    "))\n",
    "\n",
    "# Save the entire model (architecture, weights, and optimizer state)\n",
    "model.save('activity_classifier_optimized.h5')\n",
    "\n",
    "# Save only the model weights (ensure the filename ends with `.weights.h5`)\n",
    "model.save_weights('model_weights.weights.h5')\n",
    "\n",
    "print(\"Model and preprocessing artifacts saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cam test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model, scaler, and label encoder\n",
    "model = tf.keras.models.load_model('activity_classifier_optimized.h5')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Initialize Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to preprocess pose landmarks\n",
    "def preprocess_landmarks(landmarks):\n",
    "    try:\n",
    "        feature_vector = [\n",
    "            [landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in landmarks\n",
    "        ]\n",
    "        feature_vector = np.array(feature_vector).flatten().reshape(1, -1)\n",
    "        feature_vector = scaler.transform(feature_vector)  # Standardize the feature vector\n",
    "        return feature_vector\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to predict activity from processed landmarks\n",
    "def predict_activity(processed_landmarks):\n",
    "    try:\n",
    "        predictions = model.predict(processed_landmarks)\n",
    "        predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "        return label_encoder.inverse_transform([predicted_class])[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return \"Prediction Error\"\n",
    "\n",
    "# Start webcam feed\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Mediapipe Pose estimation\n",
    "with mp_pose.Pose(min_detection_confidence=0.7, min_tracking_confidence=0.7) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No frame received from webcam. Exiting.\")\n",
    "            break\n",
    "\n",
    "        # Convert image to RGB for Mediapipe\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Process pose landmarks\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR for OpenCV display\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # If pose landmarks are detected\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Preprocess landmarks and predict activity\n",
    "            processed_landmarks = preprocess_landmarks(landmarks)\n",
    "            activity = (\n",
    "                predict_activity(processed_landmarks)\n",
    "                if processed_landmarks is not None\n",
    "                else \"Processing Error\"\n",
    "            )\n",
    "        else:\n",
    "            activity = \"No Person Detected\"\n",
    "\n",
    "        # Display the activity label on the video feed\n",
    "        cv2.putText(image, f\"Activity: {activity}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Show the video feed\n",
    "        cv2.imshow('Real-time Activity Detection', image)\n",
    "\n",
    "        # Quit with 'q' key\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            print(\"Exiting application.\")\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
